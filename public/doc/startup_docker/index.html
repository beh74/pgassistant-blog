<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Startup pgAssistant with docker | pgAssistant Blog</title>
<meta name="keywords" content="Docker">
<meta name="description" content="Before you begin
You must enable the pg_stat_statements module on your postgres database. Here is a documentation
Using the NexSol Technologies docker file
Here is a sample docker-compose.yml file to run pgassistant :
services:
  pgassistant:
    image: nexsoltech/pgassistant:latest
    restart: always
    environment:
      - OPENAI_API_KEY=nothing
      - OPENAI_API_MODEL=codestral:latest
      - LOCAL_LLM_URI=http://host.docker.internal:11434/v1/
      - SECRET_KEY=mySecretKey4PgAssistant
    ports:
      - &#34;8080:5005&#34;
    volumes:
      - ./myqueries.json:/home/pgassistant/myqueries.json
The file myqueries.json is not necessary to run pgAssistant, but it should be usefull. Please read the doc here
Envrionment variables

  
      
          Variable
          Description
          Example value
      
  
  
      
          OPENAI_API_KEY
          Dummy key (required by clients expecting a token)
          nothing
      
      
          OPENAI_API_MODEL
          Model identifier to use with the API
          codestral:latest or mistral:latest
      
      
          LOCAL_LLM_URI
          Local endpoint URL for the OpenAI-compatible API
          http://host.docker.internal:11434/v1/
      
      
          SECRET_KEY
          Used to encrypt some htttp session variables.
          mySecretKey4PgAssistant
      
  

Notes

OPENAI_API_KEY is required by most clients but not used when querying local LLMs like Ollama. You can set it to any placeholder (e.g. nothing).
OPENAI_API_MODEL must match the model name loaded in Ollama (e.g. codestral, llama3, mistral, etc.).
LOCAL_LLM_URI should point to the Ollama server, accessible from inside your Docker container via host.docker.internal.


How to build your docker image
Simply clone the repo and then build your own image like this :">
<meta name="author" content="pgAssistant">
<link rel="canonical" href="http://localhost:1313/doc/startup_docker/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/doc/startup_docker/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="http://localhost:1313/doc/startup_docker/">
  <meta property="og:site_name" content="pgAssistant Blog">
  <meta property="og:title" content="Startup pgAssistant with docker">
  <meta property="og:description" content="Before you begin You must enable the pg_stat_statements module on your postgres database. Here is a documentation
Using the NexSol Technologies docker file Here is a sample docker-compose.yml file to run pgassistant :
services: pgassistant: image: nexsoltech/pgassistant:latest restart: always environment: - OPENAI_API_KEY=nothing - OPENAI_API_MODEL=codestral:latest - LOCAL_LLM_URI=http://host.docker.internal:11434/v1/ - SECRET_KEY=mySecretKey4PgAssistant ports: - &#34;8080:5005&#34; volumes: - ./myqueries.json:/home/pgassistant/myqueries.json The file myqueries.json is not necessary to run pgAssistant, but it should be usefull. Please read the doc here
Envrionment variables Variable Description Example value OPENAI_API_KEY Dummy key (required by clients expecting a token) nothing OPENAI_API_MODEL Model identifier to use with the API codestral:latest or mistral:latest LOCAL_LLM_URI Local endpoint URL for the OpenAI-compatible API http://host.docker.internal:11434/v1/ SECRET_KEY Used to encrypt some htttp session variables. mySecretKey4PgAssistant Notes OPENAI_API_KEY is required by most clients but not used when querying local LLMs like Ollama. You can set it to any placeholder (e.g. nothing). OPENAI_API_MODEL must match the model name loaded in Ollama (e.g. codestral, llama3, mistral, etc.). LOCAL_LLM_URI should point to the Ollama server, accessible from inside your Docker container via host.docker.internal. How to build your docker image Simply clone the repo and then build your own image like this :">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="doc">
    <meta property="article:published_time" content="2025-07-24T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-07-24T00:00:00+00:00">
    <meta property="article:tag" content="Docker">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Startup pgAssistant with docker">
<meta name="twitter:description" content="Before you begin
You must enable the pg_stat_statements module on your postgres database. Here is a documentation
Using the NexSol Technologies docker file
Here is a sample docker-compose.yml file to run pgassistant :
services:
  pgassistant:
    image: nexsoltech/pgassistant:latest
    restart: always
    environment:
      - OPENAI_API_KEY=nothing
      - OPENAI_API_MODEL=codestral:latest
      - LOCAL_LLM_URI=http://host.docker.internal:11434/v1/
      - SECRET_KEY=mySecretKey4PgAssistant
    ports:
      - &#34;8080:5005&#34;
    volumes:
      - ./myqueries.json:/home/pgassistant/myqueries.json
The file myqueries.json is not necessary to run pgAssistant, but it should be usefull. Please read the doc here
Envrionment variables

  
      
          Variable
          Description
          Example value
      
  
  
      
          OPENAI_API_KEY
          Dummy key (required by clients expecting a token)
          nothing
      
      
          OPENAI_API_MODEL
          Model identifier to use with the API
          codestral:latest or mistral:latest
      
      
          LOCAL_LLM_URI
          Local endpoint URL for the OpenAI-compatible API
          http://host.docker.internal:11434/v1/
      
      
          SECRET_KEY
          Used to encrypt some htttp session variables.
          mySecretKey4PgAssistant
      
  

Notes

OPENAI_API_KEY is required by most clients but not used when querying local LLMs like Ollama. You can set it to any placeholder (e.g. nothing).
OPENAI_API_MODEL must match the model name loaded in Ollama (e.g. codestral, llama3, mistral, etc.).
LOCAL_LLM_URI should point to the Ollama server, accessible from inside your Docker container via host.docker.internal.


How to build your docker image
Simply clone the repo and then build your own image like this :">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Docs",
      "item": "http://localhost:1313/doc/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Startup pgAssistant with docker",
      "item": "http://localhost:1313/doc/startup_docker/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Startup pgAssistant with docker",
  "name": "Startup pgAssistant with docker",
  "description": "Before you begin You must enable the pg_stat_statements module on your postgres database. Here is a documentation\nUsing the NexSol Technologies docker file Here is a sample docker-compose.yml file to run pgassistant :\nservices: pgassistant: image: nexsoltech/pgassistant:latest restart: always environment: - OPENAI_API_KEY=nothing - OPENAI_API_MODEL=codestral:latest - LOCAL_LLM_URI=http://host.docker.internal:11434/v1/ - SECRET_KEY=mySecretKey4PgAssistant ports: - \u0026#34;8080:5005\u0026#34; volumes: - ./myqueries.json:/home/pgassistant/myqueries.json The file myqueries.json is not necessary to run pgAssistant, but it should be usefull. Please read the doc here\nEnvrionment variables Variable Description Example value OPENAI_API_KEY Dummy key (required by clients expecting a token) nothing OPENAI_API_MODEL Model identifier to use with the API codestral:latest or mistral:latest LOCAL_LLM_URI Local endpoint URL for the OpenAI-compatible API http://host.docker.internal:11434/v1/ SECRET_KEY Used to encrypt some htttp session variables. mySecretKey4PgAssistant Notes OPENAI_API_KEY is required by most clients but not used when querying local LLMs like Ollama. You can set it to any placeholder (e.g. nothing). OPENAI_API_MODEL must match the model name loaded in Ollama (e.g. codestral, llama3, mistral, etc.). LOCAL_LLM_URI should point to the Ollama server, accessible from inside your Docker container via host.docker.internal. How to build your docker image Simply clone the repo and then build your own image like this :\n",
  "keywords": [
    "Docker"
  ],
  "articleBody": "Before you begin You must enable the pg_stat_statements module on your postgres database. Here is a documentation\nUsing the NexSol Technologies docker file Here is a sample docker-compose.yml file to run pgassistant :\nservices: pgassistant: image: nexsoltech/pgassistant:latest restart: always environment: - OPENAI_API_KEY=nothing - OPENAI_API_MODEL=codestral:latest - LOCAL_LLM_URI=http://host.docker.internal:11434/v1/ - SECRET_KEY=mySecretKey4PgAssistant ports: - \"8080:5005\" volumes: - ./myqueries.json:/home/pgassistant/myqueries.json The file myqueries.json is not necessary to run pgAssistant, but it should be usefull. Please read the doc here\nEnvrionment variables Variable Description Example value OPENAI_API_KEY Dummy key (required by clients expecting a token) nothing OPENAI_API_MODEL Model identifier to use with the API codestral:latest or mistral:latest LOCAL_LLM_URI Local endpoint URL for the OpenAI-compatible API http://host.docker.internal:11434/v1/ SECRET_KEY Used to encrypt some htttp session variables. mySecretKey4PgAssistant Notes OPENAI_API_KEY is required by most clients but not used when querying local LLMs like Ollama. You can set it to any placeholder (e.g. nothing). OPENAI_API_MODEL must match the model name loaded in Ollama (e.g. codestral, llama3, mistral, etc.). LOCAL_LLM_URI should point to the Ollama server, accessible from inside your Docker container via host.docker.internal. How to build your docker image Simply clone the repo and then build your own image like this :\ngit clone https://github.com/nexsol-technologies/pgassistant.git cd pgassistant docker build . -t mypgassistant:1.0 ",
  "wordCount" : "201",
  "inLanguage": "en",
  "datePublished": "2025-07-24T00:00:00Z",
  "dateModified": "2025-07-24T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "pgAssistant"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/doc/startup_docker/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "pgAssistant Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="pgAssistant Blog (Alt + H)">pgAssistant Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/doc/" title="Documentation">
                    <span>Documentation</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/post/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/doc/">Docs</a></div>
    <h1 class="post-title entry-hint-parent">
      Startup pgAssistant with docker
    </h1>
    <div class="post-meta"><span title='2025-07-24 00:00:00 +0000 UTC'>July 24, 2025</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;pgAssistant

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#before-you-begin" aria-label="Before you begin">Before you begin</a></li>
                <li>
                    <a href="#using-the-nexsol-technologies-docker-file" aria-label="Using the NexSol Technologies docker file">Using the NexSol Technologies docker file</a><ul>
                        <ul>
                        
                <li>
                    <a href="#envrionment-variables" aria-label="Envrionment variables">Envrionment variables</a></li>
                <li>
                    <a href="#notes" aria-label="Notes">Notes</a></li></ul>
                    </ul>
                </li>
                <li>
                    <a href="#how-to-build-your-docker-image" aria-label="How to build your docker image">How to build your docker image</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="before-you-begin">Before you begin<a hidden class="anchor" aria-hidden="true" href="#before-you-begin">#</a></h1>
<p>You must enable the <strong>pg_stat_statements</strong> module on your postgres database. <a href="/doc/pg_stat_statments">Here is a documentation</a></p>
<h1 id="using-the-nexsol-technologies-docker-file">Using the NexSol Technologies docker file<a hidden class="anchor" aria-hidden="true" href="#using-the-nexsol-technologies-docker-file">#</a></h1>
<p>Here is a sample docker-compose.yml file to run pgassistant :</p>
<pre tabindex="0"><code>services:
  pgassistant:
    image: nexsoltech/pgassistant:latest
    restart: always
    environment:
      - OPENAI_API_KEY=nothing
      - OPENAI_API_MODEL=codestral:latest
      - LOCAL_LLM_URI=http://host.docker.internal:11434/v1/
      - SECRET_KEY=mySecretKey4PgAssistant
    ports:
      - &#34;8080:5005&#34;
    volumes:
      - ./myqueries.json:/home/pgassistant/myqueries.json
</code></pre><p>The file myqueries.json is not necessary to run pgAssistant, but it should be usefull. Please read the doc <a href="/doc/myqueries">here</a></p>
<h3 id="envrionment-variables">Envrionment variables<a hidden class="anchor" aria-hidden="true" href="#envrionment-variables">#</a></h3>
<table>
  <thead>
      <tr>
          <th>Variable</th>
          <th>Description</th>
          <th>Example value</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>OPENAI_API_KEY</code></td>
          <td>Dummy key (required by clients expecting a token)</td>
          <td><code>nothing</code></td>
      </tr>
      <tr>
          <td><code>OPENAI_API_MODEL</code></td>
          <td>Model identifier to use with the API</td>
          <td><code>codestral:latest</code> or <code>mistral:latest</code></td>
      </tr>
      <tr>
          <td><code>LOCAL_LLM_URI</code></td>
          <td>Local endpoint URL for the OpenAI-compatible API</td>
          <td><code>http://host.docker.internal:11434/v1/</code></td>
      </tr>
      <tr>
          <td><code>SECRET_KEY</code></td>
          <td>Used to encrypt some htttp session variables.</td>
          <td><code>mySecretKey4PgAssistant</code></td>
      </tr>
  </tbody>
</table>
<h3 id="notes">Notes<a hidden class="anchor" aria-hidden="true" href="#notes">#</a></h3>
<ul>
<li><code>OPENAI_API_KEY</code> is required by most clients but not used when querying local LLMs like <strong>Ollama</strong>. You can set it to any placeholder (e.g. <code>nothing</code>).</li>
<li><code>OPENAI_API_MODEL</code> must match the model name loaded in Ollama (e.g. <code>codestral</code>, <code>llama3</code>, <code>mistral</code>, etc.).</li>
<li><code>LOCAL_LLM_URI</code> should point to the Ollama server, accessible from inside your Docker container via <code>host.docker.internal</code>.</li>
</ul>
<hr>
<h1 id="how-to-build-your-docker-image">How to build your docker image<a hidden class="anchor" aria-hidden="true" href="#how-to-build-your-docker-image">#</a></h1>
<p>Simply clone the repo and then build your own image like this :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/nexsol-technologies/pgassistant.git
</span></span><span style="display:flex;"><span>cd pgassistant
</span></span><span style="display:flex;"><span>docker build . -t mypgassistant:1.0
</span></span></code></pre></div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/docker/">Docker</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/doc/pg_stat_statments/">
    <span class="title">« Prev</span>
    <br>
    <span>Enable pg_stat_statements module</span>
  </a>
  <a class="next" href="http://localhost:1313/doc/myqueries/">
    <span class="title">Next »</span>
    <br>
    <span>Understanding the myqueries.json file</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">pgAssistant Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
